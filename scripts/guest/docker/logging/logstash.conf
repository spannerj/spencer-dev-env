input {
  tcp {
    type => syslog
    port => 25826
  }
}
 
filter {
  if [type] == "syslog" {
    # First we try to extract the core syslog fields. (This should in theory always work) 
    # When successful, the "message" field is removed. The meat will now be in msg.
    grok {
      match => { "message" => "%{POSINT} %{SYSLOG5424PRI:syslog_pri}%{NONNEGINT:ver} %{TIMESTAMP_ISO8601:ts} %{HOSTNAME:containerid} %{NOTSPACE:containername} %{NOTSPACE:proc} %{NOTSPACE:msgid} %{GREEDYDATA:msg}" }
      remove_field => [ "message"]
    }
    # If grokking worked, now try to get JSON fields out of msg. If successful,
    # the msg field will be removed (the final message is now back in the message field!).
    # If it fails (it might be a gunicorn log or something that isn't JSON) then change msg field back to message.
    # So the message field will always have something in it - just how much depends on how much parsing was successful.
    if ("_grokparsefailure" not in [tags]) {
      json {
        source => "msg"
        remove_field => [ "msg" ]
      }
      if ("_jsonparsefailure" in [tags]) {
        mutate {
          rename => {
            "msg" => "message"
          }
        }
      }
    }
    mutate {
      remove_field => [ "host", "port", "syslog_hostname", "syslog_message", "syslog_timestamp", "syslog_pri", "ver", "proc", "msgid", "syslog5424_pri", "type" ]
    }
  }
  multiline {
    pattern => "^\s"
    what => "previous"
  }
}
 
output {
  elasticsearch {
    hosts => ["elasticsearch-logs:9200"]
  }
}